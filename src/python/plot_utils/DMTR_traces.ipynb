{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################################################################################################################################\n",
    "###### THIS CELL CONFIGURES THE NOTEBOOK, IMPORTS LIBRARIES AND DECLARE GLOBALS THAT ARE USED THROUGHOUT THIS NOTEBOOK. UPDATE ACCORDING DO YOUR CONFIGURATION + WHAT YOU WANT TO PLOT ########\n",
    "###############################################################################################################################################################################################\n",
    "import seaborn as sns                                                                                    \n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "from os import listdir\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "rate = ''\n",
    "exp_base_folder = os.path.join('/home/maxdml/experiments/', rate, '')\n",
    "app_name = 'dmtr_http_srv'\n",
    "client_name = 'rate_client'\n",
    "stack_name = 'lwip'\n",
    "\n",
    "\n",
    "##################### Traces description\n",
    "# 1. CLT_PUSH_START - SENDING           Time between the scheduling of the request and its actual processing\n",
    "# 2. CLT_PUSH_END - CLT_PUSH_START      Time to prepare the packet, send it to the NIC driver through rte_eth_tx_burst(), and free the dpdk mbuf\n",
    "# 3. SRV_POP_START - CLT_PUSH_END       Time on the wire: item detected in the io queue's receive queue - client packet sent /!\\ I think this can be negative if the server schedule's pop way before the client sends requests\n",
    "# 4. SRV_POP_END - SRV_POP_START        Time to parse incoming packet + \"waiting time\" at the server's queue\n",
    "# 5. NET_RECEIVE - SRV_POP_END          Time between message delivered to the application by dmtr_wait_any() and packet processed by the I/O queue\n",
    "# 6. HTTP_DISPATCH - NET_RECEIVE        Time taken to select the HTTP recipient (either RR, or apply the filter, etc)\n",
    "# 7. START_HTTP - HTTP_DISPATCH         Time spent in memory queue between network component and HTTP\n",
    "# 8. END_HTTP - START_HTTP              Time spent performing HTTP processing\n",
    "# 9. HTTP_DONE - END_HTTP               Time spent in memory queue between HTTP component and HTPP /!\\ This include the \"wait time\" of dmtr_wait_any, as the same poll operates on both network sockets, and this memory queue\n",
    "# 10. SRV_PUSH_START - HTTP_DONE        Time between the scheduling of the response and its actual processing\n",
    "# 11. SRV_PUSH_END - SRV_PUSH_START     Time spent preparing the packet and sending it to the wire (identical to #2)\n",
    "# 12. CLT_POP_START - SRV_PUSH_END      Time spent on the wire /!\\ I think this can be negative as the client schedules the read as soon as it as sent the request\n",
    "# 13. CLT_POP_END - CLT_POP_START       Time spent processing an incoming network packet (includes wait time) (identical to #4)\n",
    "# 14. COMPLETED - CLT_POP_END           Time ellapsed between the reponse being delivered to the client by dmtr_wait_any(), and the response's being fully processed by the I/O queue\n",
    "\n",
    "\n",
    "# We could add a POP_WAIT for the time between a pop running but waiting, and its actual execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exps = ['test']\n",
    "exp_data = {}\n",
    "for exp in exps:\n",
    "    exp_data[exp] = pd.DataFrame()\n",
    "    # First fetch server traces\n",
    "    filename = exp +  '-traces-1' #FIXME add support for multiple network components\n",
    "    serv_traces_f = os.path.join(exp_base_folder, exp, app_name, filename)\n",
    "    server_traces = pd.read_csv(serv_traces_f, delimiter='\\t')\n",
    "#     print(server_traces)\n",
    "    \n",
    "    # Merge with demeter token traces\n",
    "    filename_pattern = '-pop-traces'\n",
    "    folderpath = os.path.join(exp_base_folder, exp, app_name)\n",
    "    # Pop files\n",
    "    pop_files = [os.path.join(folderpath, f) for f in listdir(folderpath) if os.path.isfile(os.path.join(folderpath, f)) and f.endswith(filename_pattern)]\n",
    "    df = pd.read_csv(pop_files[0], delimiter='\\t')\n",
    "    server_df = pd.merge(server_traces, df, on='POP_TOKEN')\n",
    "    server_df['SRV_POP_START'] = server_df[server_df.START == True].TIME\n",
    "    server_df['SRV_POP_END'] = server_df[server_df.START == False].TIME\n",
    "    server_df = server_df.groupby(['REQ_ID']).first().drop(['TIME', 'START', 'POP_TOKEN'], axis=1).reset_index() # get the first/last non-null value for each column within the group\n",
    "    # Push\n",
    "    filename_pattern = '-push-traces'\n",
    "    push_files = [os.path.join(folderpath, f) for f in listdir(folderpath) if os.path.isfile(os.path.join(folderpath, f)) and f.endswith(filename_pattern)]\n",
    "    df = pd.read_csv(push_files[0], delimiter='\\t') \n",
    "    server_df = pd.merge(server_df, df, on='PUSH_TOKEN')\n",
    "    server_df['SRV_PUSH_START'] = server_df[server_df.START == True].TIME\n",
    "    server_df['SRV_PUSH_END'] = server_df[server_df.START == False].TIME\n",
    "    server_df = server_df.groupby(['REQ_ID']).first().drop(['TIME', 'START', 'PUSH_TOKEN'], axis=1).reset_index() # get the first/last non-null value for each column within the group\n",
    "        \n",
    "    # Then idem for client traces\n",
    "    filename = exp + '_traces'\n",
    "    client_traces_f = os.path.join(exp_base_folder, exp, client_name, filename)\n",
    "    client_traces = pd.read_csv(client_traces_f, delimiter='\\t')\n",
    "    \n",
    "    # Merge with demeter token traces\n",
    "    filename_pattern = '-pop-traces'\n",
    "    folderpath = os.path.join(exp_base_folder, exp, client_name)\n",
    "    # Pop files\n",
    "    pop_files = [os.path.join(folderpath, f) for f in listdir(folderpath) if os.path.isfile(os.path.join(folderpath, f)) and f.endswith(filename_pattern)]\n",
    "    df = pd.read_csv(pop_files[0], delimiter='\\t')\n",
    "    client_df = pd.merge(client_traces, df, on='POP_TOKEN')\n",
    "    client_df['CLT_POP_START'] = client_df[client_df.START == True].TIME\n",
    "    client_df['CLT_POP_END'] = client_df[client_df.START == False].TIME\n",
    "    client_df = client_df.groupby(['REQ_ID']).first().drop(['TIME', 'START', 'POP_TOKEN'], axis=1).reset_index() # get the first/last non-null value for each column within the group\n",
    "    # Push\n",
    "    filename_pattern = '-push-traces'\n",
    "    push_files = [os.path.join(folderpath, f) for f in listdir(folderpath) if os.path.isfile(os.path.join(folderpath, f)) and f.endswith(filename_pattern)]\n",
    "    df = pd.read_csv(push_files[0], delimiter='\\t') \n",
    "    client_df = pd.merge(client_df, df, on='PUSH_TOKEN')\n",
    "    client_df['CLT_PUSH_START'] = client_df[client_df.START == True].TIME\n",
    "    client_df['CLT_PUSH_END'] = client_df[client_df.START == False].TIME\n",
    "    client_df = client_df.groupby(['REQ_ID']).first().drop(['TIME', 'START', 'PUSH_TOKEN'], axis=1).reset_index() # get the first/last non-null value for each column within the group\n",
    "    \n",
    "    cols = ['SENDING', 'CLT_PUSH_START', 'CLT_PUSH_END', 'SRV_POP_START', 'SRV_POP_END', 'NET_RECEIVE', 'HTTP_DISPATCH', 'START_HTTP', 'END_HTTP', 'HTTP_DONE', 'SRV_PUSH_START', 'SRV_PUSH_END', 'CLT_POP_START', 'CLT_POP_END', 'COMPLETED']\n",
    "    full_df = pd.merge(server_df, client_df, on='REQ_ID').astype('int64')\n",
    "    full_df = full_df[cols]\n",
    "    full_df = full_df.diff(axis=1)\n",
    "    full_df.drop(['SRV_POP_START', 'CLT_POP_START'], inplace=True, axis=1)\n",
    "    full_df\n",
    "    print(full_df)\n",
    "#     import seaborn as sns\n",
    "#     sns.set()\n",
    "#     full_df.T.plot(kind='bar', stacked=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
